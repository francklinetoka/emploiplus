# Tests et Validation - Filtre de Contenu Emploi+

## âœ… Checklist de DÃ©ploiement

### Frontend - Composants Core
- [x] `src/constants/bannedWords.ts` - Liste de 300+ mots interdits
- [x] `src/hooks/useProfanityFilter.ts` - Hook avec dÃ©tection et rÃ©cidives
- [x] `src/components/ui/ProfanityWarningModal.tsx` - Modale responsive
- [x] `src/components/CommentsSection.tsx` - Composant rÃ©utilisable

### IntÃ©grations Frontend
- [x] `src/pages/Newsfeed.tsx` - CrÃ©ation de posts
- [x] `src/pages/MyPublications.tsx` - Ã‰dition de publications

### Backend
- [x] `backend/src/middleware/contentFilter.ts` - Middleware de filtrage
- [x] `backend/src/middleware/CONTENT_FILTER_INTEGRATION.ts` - Guide d'intÃ©gration

### Documentation
- [x] `PROFANITY_FILTER_GUIDE.md` - Guide complet d'utilisation
- [x] Fichier de tests et validation

---

## ğŸ§ª Plan de Test

### 1. Tests Unitaires - DÃ©tection de Mots

```typescript
// Test: DÃ©tection simple
Input:  "J'adore ce merde!"
Expected: Bloquer, dÃ©tectÃ©: ["merde"]

// Test: Insensible Ã  la casse
Input:  "PUTAIN c'est cool!"
Expected: Bloquer, dÃ©tectÃ©: ["putain"]

// Test: Avec accents
Input:  "Salut c'est un bÃ¢tard de code"
Expected: Bloquer, dÃ©tectÃ©: ["bÃ¢tard", "batard"]

// Test: Avec espaces
Input:  "C'est une m e r d e de code"
Expected: Bloquer, dÃ©tectÃ©: ["merde"]

// Test: Avec caractÃ¨res spÃ©ciaux
Input:  "W**f*ck ce s#it!"
Expected: Bloquer, dÃ©tectÃ©: ["fuck", "shit"]

// Test: Contenu lÃ©gitime
Input:  "Excellent travail, bravo!"
Expected: Autoriser
```

### 2. Tests d'IntÃ©gration - Workflow Complet

#### Test A: CrÃ©ation de Post BloquÃ©e
```
1. Naviguer vers Newsfeed
2. Cliquer dans le textarea
3. Taper: "Cet emploi est une putain de merde"
4. Cliquer "Publier"
âœ“ Modale s'affiche
âœ“ Termes dÃ©tectÃ©s visibles: "putain", "merde"
âœ“ Avertissement 1/3
âœ“ Boutons Modifier / Annuler fonctionnels
âœ“ Post non crÃ©Ã© en base
```

#### Test B: Modification de Contenu (Modifier)
```
1. Depuis la modale, cliquer "Modifier"
âœ“ Modale se ferme
âœ“ Curseur retourne au textarea
âœ“ Texte reste inchangÃ©
âœ“ Utilisateur peut Ã©diter et corriger
```

#### Test C: Annulation de Contenu (Annuler)
```
1. Depuis la modale, cliquer "Annuler"
âœ“ Modale se ferme
âœ“ Textarea se vide
âœ“ Formulaire revient Ã  l'Ã©tat vide
âœ“ Images supprimÃ©es si prÃ©sentes
```

#### Test D: RÃ©cidives et Suspension
```
1. Premier avertissement
   âœ“ Modale affiche: Avertissements 1/3
   
2. DeuxiÃ¨me avertissement
   âœ“ Modale affiche: Avertissements 2/3
   
3. TroisiÃ¨me avertissement
   âœ“ Modale affiche: Compte temporairement suspendu
   âœ“ Compte suspendu pour 1 heure
   âœ“ Pas d'avertissements aprÃ¨s 3
   
4. AprÃ¨s 1 heure
   âœ“ Suspension levÃ©e automatiquement
   âœ“ Compteur rÃ©initialisÃ©
```

### 3. Tests UI/UX - Modale

#### AccessibilitÃ©
```
âœ“ ARIA labels prÃ©sents (role="alertdialog")
âœ“ Focus trap (ne sort pas de la modale)
âœ“ Touche Ã‰chap ferme la modale
âœ“ Indicateur visuel d'avertissement (rouge)
âœ“ Contraste suffisant (WCAG AA)
```

#### Responsive
```
âœ“ Mobile (320px) : Modale lisible
âœ“ Tablet (768px) : Modale bien proportionnÃ©e
âœ“ Desktop (1024px+) : Centrage parfait
âœ“ Pas de dÃ©bordement de texte
```

#### Visual
```
âœ“ IcÃ´ne âš ï¸ rouge visible
âœ“ Termes dÃ©tectÃ©s en rouge/orange
âœ“ Boutons bien espacÃ©s
âœ“ Message clair et Ã©ducatif
âœ“ Animation fade in/out
```

### 4. Tests Backend - Middleware

#### Test E: IntÃ©gration Middleware
```
1. POST /api/publications (sans middleware)
   - Contenu banni passe
   - âŒ MAUVAIS

2. POST /api/publications (avec middleware)
   - Contenu banni bloquÃ©
   - âœ“ RÃ©ponse 400 avec erreur BANNED_CONTENT
   - âœ“ triggeredWords dans rÃ©ponse

3. POST /api/publications (contenu lÃ©gitime + middleware)
   - Autoriser et crÃ©er le post
   - âœ“ RÃ©ponse 201/200
```

#### Test F: Double SÃ©curitÃ©
```
1. Contourner le filtre client avec API
   - Envoi direct PUT /api/publications/1
   - Contenu interdit en body
   âœ“ Middleware bloque
   âœ“ RÃ©ponse 400 BANNED_CONTENT
   âœ“ Post non modifiÃ© en base
```

### 5. Tests de Contenu - Cas Limites

```typescript
// Cas 1: Acronymes
"Lol, c'est cool!" â†’ Autoriser (pas d'avertissement)

// Cas 2: Mots composÃ©s lÃ©gitimes
"J'habite Ã  Connart (commune)" â†’ Bloquer (dÃ©t: "connard")
// Note: Limitation connue - faux positif possible

// Cas 3: Contenu acadÃ©mique
"Le mot 'nÃ¨gre' est utilisÃ© historiquement..." â†’ Bloquer
// Note: Limitation - pas de contexte

// Cas 4: Langues mÃ©langÃ©es
"C'est fucking incroyable!" â†’ Bloquer (dÃ©t: "fucking")

// Cas 5: TranslittÃ©ration
"Putain" (UTF-8) â†’ Bloquer

// Cas 6: Variantes orthographiques
"putan" (incomplet) â†’ Autoriser si pas de match substring
```

### 6. Tests de Performance

```
// DÃ©tection de 100 posts
- Temps: < 1000ms total
- MÃ©moire: < 10MB

// Normalisation de 10000 caractÃ¨res
- Temps: < 50ms

// Stockage localStorage
- Warnings: ~1KB per week
- Pas d'impact sur performance
```

---

## ğŸš€ Ã‰tapes de DÃ©ploiement

### Avant le DÃ©ploiement

```bash
# 1. Compiler TypeScript
cd src && npx tsc --noEmit
cd backend && npx tsc --noEmit

# 2. Tester les imports
npm run build

# 3. VÃ©rifier pas d'erreurs TypeScript
npm run type-check

# 4. Tester localement
npm run dev

# 5. Tourner les tests
npm run test
```

### DÃ©ploiement

```bash
# 1. Push sur git
git add -A
git commit -m "feat: Add content filter and automatic moderation"
git push origin feature/profanity-filter

# 2. CrÃ©er PR et faire revue

# 3. Merge sur main

# 4. DÃ©ployer sur production
npm run build
npm run deploy

# 5. Monitorer les logs
tail -f logs/server.log | grep "CONTENT_FILTER"
```

### Post-DÃ©ploiement

```
â–¡ VÃ©rifier les logs en production
â–¡ Tester avec comptes de test
â–¡ Monitorer les faux positifs
â–¡ Ajuster la liste selon les retours
â–¡ Valider les suspensions
â–¡ Documenter les cas spÃ©ciaux
```

---

## ğŸ“Š MÃ©triques Ã  Surveiller

### KPIs
```
Daily:
- Nombre de tentatives de contenu banni
- Nombre de violations uniques par utilisateur
- Mots les plus dÃ©tectÃ©s
- Faux positifs signalÃ©s

Weekly:
- Taux de users "violateurs"
- Impact sur engagement (posts/comments)
- Performance du filtre
- Feedback utilisateur

Monthly:
- Tendances des violations
- EfficacitÃ© du systÃ¨me de suspension
- Ajustements de liste nÃ©cessaires
- CoÃ»t de modÃ©ration humaine Ã©vitÃ©
```

### Queries de Monitoring

```sql
-- Violations par jour
SELECT 
  DATE(created_at) as date,
  COUNT(*) as violations,
  COUNT(DISTINCT user_id) as unique_users
FROM profanity_violations
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY DATE(created_at)
ORDER BY date DESC;

-- Utilisateurs Ã  surveiller
SELECT 
  user_id,
  COUNT(*) as violation_count,
  MAX(created_at) as last_violation
FROM profanity_violations
WHERE created_at > NOW() - INTERVAL '24 hours'
GROUP BY user_id
ORDER BY violation_count DESC
LIMIT 20;

-- Mots les plus problÃ©matiques
SELECT 
  JSONB_ARRAY_ELEMENTS(triggered_words) as word,
  COUNT(*) as frequency
FROM profanity_violations
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY word
ORDER BY frequency DESC
LIMIT 20;
```

---

## ğŸ› DÃ©pannage

### ProblÃ¨me: La modale ne s'affiche pas

**Causes possibles:**
- Import manquant du hook ou modale
- State non initialisÃ©
- Erreur TypeScript

**Solution:**
```bash
# VÃ©rifier les imports
grep -r "ProfanityWarningModal" src/pages/

# VÃ©rifier la compilation
npm run build

# VÃ©rifier la console navigateur (F12)
```

### ProblÃ¨me: Faux positifs excessifs

**Solution:**
1. Identifier les mots problÃ©matiques
2. Ajouter des exceptions (contexte)
3. Remplacer par NLP si nÃ©cessaire

```typescript
// Exemple: Excepper certains contextes
const isLegitimate = (word: string, context: string) => {
  if (word === "nÃ©gro" && context.includes("historiquement")) {
    return true;
  }
  return false;
};
```

### ProblÃ¨me: RÃ©cidives ne se rÃ©initialisent pas

**Solution:**
```typescript
// VÃ©rifier localStorage
localStorage.getItem('profanity_warnings')

// RÃ©initialiser manuellement
localStorage.removeItem('profanity_warnings')
localStorage.removeItem('profanity_suspension')

// VÃ©rifier les timestamps
const stored = JSON.parse(localStorage.getItem('profanity_warnings') || '[]');
stored.forEach(w => console.log(new Date(w.timestamp)));
```

---

## ğŸ“‹ Sign-off de Test

### Frontend
- [ ] Tests unitaires passing (100%)
- [ ] Tests d'intÃ©gration passing
- [ ] UI responsive validÃ©e (mobile/tablet/desktop)
- [ ] AccessibilitÃ© vÃ©rifiÃ©e (WCAG AA)
- [ ] Perf acceptable < 200ms par dÃ©tection

### Backend
- [ ] Middleware testÃ© en isolation
- [ ] Routes testÃ©es avec donnÃ©es rÃ©elles
- [ ] Erreurs gÃ©rÃ©es correctement
- [ ] Logs complets et lisibles
- [ ] Double sÃ©curitÃ© vÃ©rifiÃ©e

### QA
- [ ] ScÃ©narios utilisateur complets testÃ©s
- [ ] Cas limites couverts
- [ ] Faux positifs < 5%
- [ ] Aucun rÃ©gression dÃ©tectÃ©e
- [ ] Documentation Ã  jour

### Production
- [ ] DÃ©ploiement fluide
- [ ] Monitoring actif 7j/7
- [ ] Rollback plan en place
- [ ] Support prÃªt pour escalades
- [ ] SLA respectÃ©

---

## ğŸ¯ Objectifs Atteints

âœ… **DÃ©tection en temps rÃ©el** : Client-side avec validation serveur  
âœ… **Gestion des rÃ©cidives** : LocalStorage + localStorage + suspension 1h  
âœ… **UX Accessible** : ARIA, focus trap, responsive  
âœ… **Double sÃ©curitÃ©** : Client + serveur  
âœ… **Composant rÃ©utilisable** : CommentsSection  
âœ… **Documentation complÃ¨te** : Guides + exemples + tests  
âœ… **Extensible** : Facile d'ajouter des mots ou des rÃ¨gles  
âœ… **Professional** : Conforme aux standards industrie (LinkedIn, Meta)  

---

**DerniÃ¨re mise Ã  jour** : 17 janvier 2026  
**Status** : âœ… COMPLET - PrÃªt pour test/dÃ©ploiement
